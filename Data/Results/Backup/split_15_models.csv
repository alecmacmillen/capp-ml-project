model,train_date,test_date,parameters,threshold,baseline,accuracy,precision,recall,f1,auc
Random forest,01/01/2000 - 01/01/2016,01/01/2017 - 01/01/2018,"{'criterion': 'gini', 'n_estimators': 10, 'max_depth': None, 'random_state': 100}",0.05,0.7247213757538304,0.7505913440023867,0.7587382779198636,0.13779222789905557,0.2332285115303983,0.5605747872418917
ADA Boost,01/01/2000 - 01/01/2016,01/01/2017 - 01/01/2018,"{'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.1, 'loss': 'exponential'}",0.05,0.7247213757538304,0.7500372919641145,0.7531969309462916,0.13678588016720855,0.2315251572327044,0.5598804874975242
Gradient boosting,01/01/2000 - 01/01/2016,01/01/2017 - 01/01/2018,"{'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.1, 'loss': 'deviance'}",0.05,0.7247213757538304,0.749781575638758,0.7506393861892583,0.13632141198327916,0.23073899371069184,0.5595600414616622
Random forest,01/01/2000 - 01/01/2016,01/01/2017 - 01/01/2018,"{'criterion': 'entropy', 'n_estimators': 10, 'max_depth': None, 'random_state': 100}",0.05,0.7247213757538304,0.7487160909497731,0.7399829497016198,0.13438612788357332,0.22746331236897277,0.5582248496455711
Random forest,01/01/2000 - 01/01/2016,01/01/2017 - 01/01/2018,"{'criterion': 'gini', 'n_estimators': 10, 'max_depth': None, 'random_state': 100}",0.1,0.7247213757538304,0.7708781724806615,0.7308184143222506,0.2654435671156526,0.3894378194207836,0.6141531693674649
Gradient boosting,01/01/2000 - 01/01/2016,01/01/2017 - 01/01/2018,"{'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.1, 'loss': 'deviance'}",0.1,0.7247213757538304,0.7636328765955633,0.6945865302642796,0.2522836352376529,0.37013060760931293,0.6050738650180444
Random forest,01/01/2000 - 01/01/2016,01/01/2017 - 01/01/2018,"{'criterion': 'gini', 'n_estimators': 10, 'max_depth': None, 'random_state': 100}",0.15,0.7247213757538304,0.7815117096767319,0.6893024577354738,0.3755999380709088,0.4862454276694894,0.6556467154849237
Logistic regression,01/01/2000 - 01/01/2016,01/01/2017 - 01/01/2018,"{'C': 1.0, 'penalty': 'l2'}",0.05,0.7247213757538304,0.7431329511794915,0.6841432225063938,0.12424523920111473,0.21029874213836477,0.5512284445292527
Logistic regression,01/01/2000 - 01/01/2016,01/01/2017 - 01/01/2018,"{'C': 1.0, 'penalty': 'l1'}",0.05,0.7247213757538304,0.7430903317919322,0.6837169650468883,0.12416782783712649,0.21016771488469604,0.5511750368566091
Random forest,01/01/2000 - 01/01/2016,01/01/2017 - 01/01/2018,"{'criterion': 'entropy', 'n_estimators': 10, 'max_depth': None, 'random_state': 100}",0.1,0.7247213757538304,0.7613740490549151,0.6832907075873828,0.24818083294627652,0.3641113003975014,0.6022432583679309
ADA Boost,01/01/2000 - 01/01/2016,01/01/2017 - 01/01/2018,"{'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.1, 'loss': 'exponential'}",0.1,0.7247213757538304,0.7598397511027767,0.675618073316283,0.24539402384270012,0.360022714366837,0.6003205821527594
Gradient boosting,01/01/2000 - 01/01/2016,01/01/2017 - 01/01/2018,"{'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.1, 'loss': 'deviance'}",0.15,0.7247213757538304,0.7732861678777676,0.6618837903111238,0.36065954482117973,0.4669038432630155,0.6453390346646991
Bagging,01/01/2000 - 01/01/2016,01/01/2017 - 01/01/2018,"{'n_estimators': 10, 'max_samples': 1.0, 'max_features': 1.0, 'random_state': 100, 'base_estimator': None}",0.05,0.7247213757538304,0.7407888848637245,0.6606990622335891,0.11998761418176188,0.20309224318658278,0.548291022533852
Random forest,01/01/2000 - 01/01/2016,01/01/2017 - 01/01/2018,"{'criterion': 'entropy', 'n_estimators': 10, 'max_depth': None, 'random_state': 100}",0.15,0.7247213757538304,0.7703028107486095,0.6519391959085097,0.3552407493420034,0.45988876083579694,0.6416004975796435
ADA Boost,01/01/2000 - 01/01/2016,01/01/2017 - 01/01/2018,"{'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.1, 'loss': 'exponential'}",0.15,0.7247213757538304,0.7685554158586742,0.6461145049012644,0.35206688341848585,0.45577992684271185,0.6394107830012539
Bagging,01/01/2000 - 01/01/2016,01/01/2017 - 01/01/2018,"{'n_estimators': 10, 'max_samples': 1.0, 'max_features': 1.0, 'random_state': 100, 'base_estimator': None}",0.1,0.7247213757538304,0.75391565623202,0.6459931798806479,0.23463384424833567,0.34423622941510507,0.592896915655292
Bagging,01/01/2000 - 01/01/2016,01/01/2017 - 01/01/2018,"{'n_estimators': 10, 'max_samples': 1.0, 'max_features': 1.0, 'random_state': 100, 'base_estimator': None}",0.15,0.7247213757538304,0.7627591791505957,0.6267935786333286,0.3415389379160861,0.4421506238412587,0.6321473395217173
Logistic regression,01/01/2000 - 01/01/2016,01/01/2017 - 01/01/2018,"{'C': 1.0, 'penalty': 'l2'}",0.1,0.7247213757538304,0.7488013297248919,0.6204177323103154,0.22534448056974765,0.3306076093128904,0.5864879949380539
Logistic regression,01/01/2000 - 01/01/2016,01/01/2017 - 01/01/2018,"{'C': 1.0, 'penalty': 'l1'}",0.1,0.7247213757538304,0.7486734715622136,0.6197783461210571,0.22511224647778294,0.3302668938103351,0.5863277719201229
Logistic regression,01/01/2000 - 01/01/2016,01/01/2017 - 01/01/2018,"{'C': 1.0, 'penalty': 'l2'}",0.15,0.7247213757538304,0.7525731455238989,0.5928398920301179,0.32303762192289825,0.4181991281254697,0.6193829057598849
Logistic regression,01/01/2000 - 01/01/2016,01/01/2017 - 01/01/2018,"{'C': 1.0, 'penalty': 'l1'}",0.15,0.7247213757538304,0.7524452873612206,0.5924136951271487,0.3228053878309336,0.41789848173573185,0.6192226827419539
Gaussian Naive Bayes,01/01/2000 - 01/01/2016,01/01/2017 - 01/01/2018,{},0.1,0.7247213757538304,0.7324781042896413,0.5387894288150042,0.19569592816225423,0.28710959681998866,0.5660328563155357
Decision tree,01/01/2000 - 01/01/2016,01/01/2017 - 01/01/2018,"{'criterion': 'entropy', 'max_depth': None, 'splitter': 'best'}",0.15,0.7247213757538304,0.7329682272465745,0.5274897002415115,0.28742839448831087,0.3721000150323195,0.5948153763438055
Gaussian Naive Bayes,01/01/2000 - 01/01/2016,01/01/2017 - 01/01/2018,{},0.05,0.7247213757538304,0.7268097257442411,0.5208866155157715,0.0945966867936213,0.1601153039832285,0.5307733059067344
Decision tree,01/01/2000 - 01/01/2016,01/01/2017 - 01/01/2018,"{'criterion': 'entropy', 'max_depth': None, 'splitter': 'best'}",0.1,0.7247213757538304,0.7277047328829884,0.514919011082694,0.18702585539557207,0.274389551391255,0.5600511969794468
Gaussian Naive Bayes,01/01/2000 - 01/01/2016,01/01/2017 - 01/01/2018,{},0.15,0.7247213757538304,0.7279817589021246,0.5108680210257138,0.27837126490168757,0.36037480583254,0.5885666786444983
Decision tree,01/01/2000 - 01/01/2016,01/01/2017 - 01/01/2018,"{'criterion': 'gini', 'max_depth': None, 'splitter': 'best'}",0.15,0.7247213757538304,0.72759818441409,0.5095894303168064,0.2776745626257935,0.35947286666332623,0.5880860095907056
Decision tree,01/01/2000 - 01/01/2016,01/01/2017 - 01/01/2018,"{'criterion': 'gini', 'max_depth': None, 'splitter': 'best'}",0.1,0.7247213757538304,0.7258294798303748,0.505541346973572,0.1836197553800898,0.2693923906871096,0.5577012593831261
Decision tree,01/01/2000 - 01/01/2016,01/01/2017 - 01/01/2018,"{'criterion': 'gini', 'max_depth': None, 'splitter': 'best'}",0.05,0.7247213757538304,0.7243378012657958,0.4961636828644501,0.09010682768230376,0.15251572327044025,0.5276756608934028
Decision tree,01/01/2000 - 01/01/2016,01/01/2017 - 01/01/2018,"{'criterion': 'entropy', 'max_depth': None, 'splitter': 'best'}",0.05,0.7247213757538304,0.7236558910648454,0.48934356351236147,0.08886824585849203,0.15041928721174003,0.5268211381311043
